{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc020466",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!pip install pip3-autoremove\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install unsloth\n",
    "!pip install --upgrade transformers==4.52.4\n",
    "!pip install kagglehub --upgrade\n",
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab109bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
    "from datasets import load_dataset\n",
    "from keybert import KeyBERT\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Llama-3.2-11B-Vision-Instruct\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f6fe6",
   "metadata": {},
   "source": [
    "***Check tokenizer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizer type:\", type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b8804a",
   "metadata": {},
   "source": [
    "***Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1568a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"unsloth/Radiology_mini\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d87015",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea4dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"image_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80344c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"cui\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"caption\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53032ee5",
   "metadata": {},
   "source": [
    "```python\n",
    "{ \"role\": \"user\",\n",
    "          \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : instruction}]\n",
    "        },\n",
    "        { \"role\" : \"assistant\",\n",
    "          \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : sample[\"caption\"]},\n",
    "            { \"type\": \"text\", \"text\": \"{{keywords}}\" },\n",
    "            {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
    "          ]\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39a644",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo thư mục lưu kết quả\n",
    "output_jsonl_path = \"/kaggle/working/radiology_conversations.jsonl\"\n",
    "image_dir = \"/kaggle/working/images\"\n",
    "os.makedirs(image_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = (\n",
    "    \"Hãy đưa ra câu trả lời chính xác và chi tiết nhất cho truy vấn của người dùng. \"\n",
    "    \"Trả lời dựa trên thông tin hình ảnh phù hợp đã tìm thấy, \"\n",
    "    \"nhưng đừng hiển thị các từ khóa đã được phân tích.\"\n",
    ")\n",
    "\n",
    "\n",
    "def convert_to_conversation_for_training(image_path, caption, instruction):\n",
    "    \"\"\"Format cho việc training/lưu trữ data\"\"\"\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": instruction}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": caption},\n",
    "                {\"type\": \"image\", \"image\": image_path}\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    return {\"messages\": conversation}\n",
    "\n",
    "def convert_to_conversation_for_inference(instruction, image_path=None):\n",
    "    \"\"\"Format cho việc inference với model\"\"\"\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruction\n",
    "        }\n",
    "    ]\n",
    "    return {\"messages\": conversation}\n",
    "\n",
    "# Ghi lần lượt vào file\n",
    "with open(output_jsonl_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for i, sample in enumerate(dataset):\n",
    "        image_id = sample[\"image_id\"]\n",
    "        caption = sample[\"caption\"]\n",
    "        image = sample[\"image\"]\n",
    "\n",
    "        # Lưu ảnh\n",
    "        image_path = os.path.join(image_dir, f\"{image_id}.png\")\n",
    "        image.save(image_path)\n",
    "\n",
    "        # OPTIONAL: Trích xuất từ khóa\n",
    "        keywords = kw_model.extract_keywords(\n",
    "            caption,\n",
    "            keyphrase_ngram_range=(1, 2),\n",
    "            stop_words='english',\n",
    "            top_n=3\n",
    "        )\n",
    "        # print(f\"[{i}] Caption:\", caption)\n",
    "        # print(\"→ Keywords:\", [kw for kw, _ in keywords])\n",
    "\n",
    "        # # Format sample\n",
    "        # convo = convert_to_conversation_for_training(image_path, caption, instruction)\n",
    "        # convo[\"keywords\"] = [kw for kw, _ in keywords]\n",
    "\n",
    "        keyword_list = [kw for kw, score in keywords]\n",
    "        print(f\"[{i}] Caption: {caption[:100]}...\")\n",
    "        print(f\"→ Keywords: {keyword_list}\")\n",
    "        \n",
    "        # Format sample\n",
    "        convo = convert_to_conversation_for_training(image_path, caption, instruction)\n",
    "        convo[\"keywords\"] = keyword_list\n",
    "        convo[\"image_id\"] = image_id\n",
    "\n",
    "        # Ghi ra file\n",
    "        f_out.write(json.dumps(convo, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\nĐã lưu {len(dataset)} conversation vào: {output_jsonl_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from difflib import SequenceMatcher\n",
    "\n",
    "# # Load dữ liệu từ file jsonl\n",
    "# def load_conversation_json(jsonl_path):\n",
    "#     dataset = []\n",
    "#     with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         for line in f:\n",
    "#             dataset.append(json.loads(line.strip()))\n",
    "#     return dataset\n",
    "\n",
    "# # Tìm kiếm theo độ tương đồng keyword\n",
    "# class SimpleSearchEngine:\n",
    "#     def __init__(self, dataset):\n",
    "#         self.dataset = dataset\n",
    "\n",
    "#     def search(self, query):\n",
    "#         def match_score(query, keywords):\n",
    "#             return SequenceMatcher(None, query, \" \".join(keywords)).ratio()\n",
    "\n",
    "#         best = max(self.dataset, key=lambda sample: match_score(query, sample[\"keywords\"]))\n",
    "#         caption = best[\"messages\"][1][\"content\"][0][\"text\"]\n",
    "#         image_path = best[\"messages\"][1][\"content\"][1][\"image\"]\n",
    "#         image = Image.open(image_path)\n",
    "\n",
    "#         return {\n",
    "#             \"caption\": caption,\n",
    "#             \"image\": image\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm kiếm theo độ tương đồng keyword\n",
    "class ImprovedSearchEngine:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def calculate_similarity(self, query, keywords):\n",
    "        \"\"\"Tính độ tương đồng giữa query và keywords\"\"\"\n",
    "        query_lower = query.lower().strip()\n",
    "        max_score = 0\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            keyword_lower = keyword.lower().strip()\n",
    "            \n",
    "            # Exact match\n",
    "            if query_lower == keyword_lower:\n",
    "                return 1.0\n",
    "            \n",
    "            # Substring match\n",
    "            if query_lower in keyword_lower or keyword_lower in query_lower:\n",
    "                score = 0.8\n",
    "            else:\n",
    "                # Sequence similarity\n",
    "                score = SequenceMatcher(None, query_lower, keyword_lower).ratio()\n",
    "            \n",
    "            max_score = max(max_score, score)\n",
    "        \n",
    "        return max_score\n",
    "    \n",
    "    def search(self, query, top_k=1):\n",
    "        \"\"\"Tìm kiếm theo query\"\"\"\n",
    "        scored_results = []\n",
    "        \n",
    "        for sample in self.dataset:\n",
    "            keywords = sample.get(\"keywords\", [])\n",
    "            score = self.calculate_similarity(query, keywords)\n",
    "            \n",
    "            # Lấy thông tin từ messages\n",
    "            assistant_content = sample[\"messages\"][1][\"content\"]\n",
    "            caption = assistant_content[0][\"text\"]\n",
    "            image_path = assistant_content[1][\"image\"]\n",
    "            \n",
    "            scored_results.append({\n",
    "                \"score\": score,\n",
    "                \"caption\": caption,\n",
    "                \"image_path\": image_path,\n",
    "                \"keywords\": keywords,\n",
    "                \"image_id\": sample.get(\"image_id\", \"unknown\")\n",
    "            })\n",
    "        \n",
    "        # Sort theo score\n",
    "        scored_results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        \n",
    "        if top_k == 1:\n",
    "            return scored_results[0] if scored_results else None\n",
    "        else:\n",
    "            return scored_results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ef379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset và khởi tạo search engine\n",
    "print(\"\\nLoading processed dataset...\")\n",
    "dataset_path = \"/kaggle/working/radiology_conversations.jsonl\"  # sửa lại path đúng nếu khác\n",
    "dataset = load_conversation_json(dataset_path)\n",
    "search_engine = SimpleSearchEngine(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample[\"image\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3786f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "# #image = dataset[0][\"image\"]\n",
    "# #instruction = \"You are an expert radiographer. Describe accurately what you see in this image.\"\n",
    "\n",
    "# query = \"cardiac thrombi\"\n",
    "# retrieved = search_engine.search(query)\n",
    "\n",
    "# instruction = (\n",
    "#     \"Dưới đây là một hình ảnh y tế. Vui lòng phân tích nội dung hình ảnh và đưa ra câu trả lời phù hợp. \"\n",
    "#     \"Không hiển thị từ khóa đã được phân tích.\"\n",
    "# )\n",
    "# #image = Image.open(retrieved[\"image\"]).convert(\"RGB\")\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "# # Nếu retrieved[\"image\"] là đường dẫn → load ảnh\n",
    "# if isinstance(retrieved[\"image\"], str):\n",
    "#     image = Image.open(retrieved[\"image\"]).convert(\"RGB\")\n",
    "\n",
    "# # Nếu nó là ảnh kiểu PngImageFile → convert lại\n",
    "# elif isinstance(retrieved[\"image\"], Image.Image):\n",
    "#     image = retrieved[\"image\"].convert(\"RGB\")\n",
    "# else:\n",
    "#     raise TypeError(\"Không xác định được định dạng ảnh!\")\n",
    "\n",
    "# sample = {\n",
    "#     \"caption\": retrieved[\"caption\"],  # từ search_engine ra\n",
    "#     #\"image\": retrieved[\"image\"]       # PIL.Image.Image object\n",
    "#     \"image\": image\n",
    "# }\n",
    "\n",
    "# formatted = convert_to_conversation(\n",
    "#     caption=sample[\"caption\"],\n",
    "#     image_path=sample[\"image\"],\n",
    "#     instruction=instruction\n",
    "# )\n",
    "# messages = formatted[\"messages\"]\n",
    "\n",
    "# user_prompt = [msg for msg in messages if msg[\"role\"] == \"user\"]\n",
    "# input_text = tokenizer.apply_chat_template(user_prompt, add_generation_prompt=True)\n",
    "# #image = sample[\"image\"]\n",
    "\n",
    "# inputs = tokenizer(\n",
    "#     image=sample[\"image\"],         # PIL.Image.Image object\n",
    "#     text=input_text,               # generated by apply_chat_template\n",
    "#     add_special_tokens=False,\n",
    "#     return_tensors=\"pt\"\n",
    "# ).to(\"cuda\")\n",
    "\n",
    "# from transformers import TextStreamer\n",
    "# text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "# _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "#                    use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "def analyze_medical_image(query):\n",
    "    \"\"\"Main function để phân tích hình ảnh y tế\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Searching for: '{query}'\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Tìm kiếm ảnh phù hợp\n",
    "    retrieved = search_engine.search(query)\n",
    "    \n",
    "    if not retrieved:\n",
    "        print(\"No matching images found!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found match with score: {retrieved['score']:.3f}\")\n",
    "    print(f\"Image ID: {retrieved['image_id']}\")\n",
    "    print(f\"Keywords: {retrieved['keywords']}\")\n",
    "    print(f\"Original caption: {retrieved['caption'][:100]}...\")\n",
    "    \n",
    "    # Load image\n",
    "    image_path = retrieved[\"image_path\"]\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file not found: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        print(f\"Image loaded: {image.size}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Instruction cho analysis\n",
    "    analysis_instruction = (\n",
    "        \"Dưới đây là một hình ảnh y tế về {}. \"\n",
    "        \"Vui lòng phân tích chi tiết nội dung hình ảnh và đưa ra nhận xét chuyên môn. \"\n",
    "        \"Mô tả những gì bạn quan sát được một cách chính xác và khoa học.\"\n",
    "    ).format(query)\n",
    "    \n",
    "    # Chuẩn bị input cho model\n",
    "    formatted = convert_to_conversation_for_inference(analysis_instruction)\n",
    "    messages = formatted[\"messages\"]\n",
    "    \n",
    "    # Apply chat template\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        image=image,\n",
    "        text=input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    # Generate với streaming\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"MEDICAL IMAGE ANALYSIS:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                streamer=text_streamer,\n",
    "                max_new_tokens=256,\n",
    "                use_cache=True,\n",
    "                temperature=0.7,  # Lower temperature for medical analysis\n",
    "                min_p=0.1,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"retrieved\": retrieved,\n",
    "            \"image\": image,\n",
    "            \"outputs\": outputs\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "        \"cardiac thrombi\",\n",
    "        \"lung infection\", \n",
    "        \"brain tumor\",\n",
    "        \"chest x-ray\"\n",
    "    ]\n",
    "    \n",
    "for query in test_queries:\n",
    "    result = analyze_medical_image(query)\n",
    "    if result:\n",
    "        print(f\"\\nSuccessfully analyzed: {query}\")\n",
    "    else:\n",
    "        print(f\"\\nFailed to analyze: {query}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfcb4a",
   "metadata": {},
   "source": [
    "***Load Model LoRA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Đăng nhập (chỉ cần làm 1 lần)\n",
    "kagglehub.login()\n",
    "\n",
    "#Load model về notebook\n",
    "model_path = kagglehub.model_download(\n",
    "    handle=\"giahuytranviet/llama3-lora-vision/pyTorch/default\"\n",
    ")\n",
    "\n",
    "print(\"Model directory:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c635b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastVisionModel\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Load LoRA đã fine-tune\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    model_name = model_path,  # thư mục bạn đã lưu\n",
    "    load_in_4bit = True,         # hoặc False nếu bạn không dùng quantization\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "FastVisionModel.for_inference(model)  # Bắt buộc để chuyển về chế độ dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cae395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"unsloth/Radiology_mini\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][\"caption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff35112",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset[1][\"image\"]\n",
    "instruction = \"Bạn là một chuyên gia X-quang. Hãy mô tả những gì bạn thấy trong ảnh này.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 1280,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
